```python
各个模型原理必须熟知，后面的专项才能归纳到位！！！
```

## 机器学习

吴恩达机器学习
感知机
SVM
树模型
集成模型
PCA
KNN

- 机器学习属于module learning，有一个大的假设空间，search the best假设用来解释这些数据，这个假设的表现形式就是一个函数或者说数学模型，可以用来预测(回归)或者分类
- 分成几个大类
   - reinforcement Learning 
     - 对结果带有奖惩机制
     - 比如下棋
   - supervised learning
     - 线性模型
       - 找寻feature和label的关系，可能是线性函数(y=ax+b)，可能是高阶线性关系
       - 如何评价呢？loss fun越小越好
       - 如何求解呢？梯度下降，如果数据量小直接LMS 线性奇异值分解
         - 梯度下降呢，又有mini batch，随机梯度下降，学习率变化的梯度下降
         - 跳出局部最优解呢
             - 调整学习率
             - 遗传算法的化，通过变异。
     - svm
   - unsupervised learing

- 不同的模型都是这么个顺序
   - module
   - loss fun
   - 求解loss最小，如何求呢最优值呢？梯度下降
     - 求导，求微分
     -

## 专题：归一化&标准化&中心化/0-均值化

- 本质就是数据缩放，都是一种数据的线性变化
  - 线性变化不改变原始数据的数值排序

- 为什么需要变换
   - 减少计算量
   - 加速迭代，未归一化/标准化时形成的等高线偏椭圆，迭代时很有可能走“之”字型路线（垂直长轴），从而导致迭代很多次才能收敛，标准化之后，等高线变成圆，加快收敛。
   - 避免数据范围(量纲)对结果产生的影响，比如分类的时候计算距离，个别特征数值太大。比如房价和面积，量纲不同，可以归一化处理

- 归一化 normalization
  - $ x = (x-x_min)/(x_max - x_min) $
  - 看中的是把数据缩放到0-1区间，拍平
- 标准化 z-score standardization
  - $ x = (x - u)/ \alpha $
  - 关注每一个x，关注数据的分布，标准化之后不是0-1区间
- 中心化/0-均值化 zero-centered
  - $ x = (x - u)$

- 什么时候用归一化？什么时候用标准化
   - 如果对数据输出范围有要求，或者数据比较稳定，没有极端的最大最小值，用归一化
   - 如果关注数据本身的分布，数据存在异常值或噪声值，用标准化，可以间接通过中心化避免异常值和极端值的影响
   - 按模型来说
     - svm：因为不同模型的特征分布假设不同，比如svm使用高斯核的时候，所有维度公用一个方差
     - KNN：需要度量距离、协方差计算的模型，一般需要归一化/标准化，不然会出现大数吃小数
     - 神经网络：数值问题、梯度求解需要、学习率
     - PCA 降维的时候Z-score standardization更好。


```python

```
